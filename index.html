<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Harsh Tomar - AI/ML Developer</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
</head>

<body>
    <div class="container">
        <header>
            <div class="profile">
                <img src="https://avatars.githubusercontent.com/u/123729493?v=4" alt="Harsh Tomar" class="avatar">
                <h1>Harsh Tomar</h1>
                <p class="tagline">I build AI systems that actually work — from tracking tennis balls at 30 FPS to
                    generating novel molecules</p>
                <p class="bio">Self-taught AI/ML developer who learns by building. I've implemented Vision Transformers,
                    VLMs, and LoRA from scratch in PyTorch. My Tennis Vision project got 23+ stars for detecting players
                    with 95% accuracy and tracking balls in real-time. Currently exploring LLM reasoning, RAG pipelines,
                    and agentic AI. I break things, fix them, and document it all.</p>
                <div class="social-links">
                    <a href="https://github.com/HarshTomar1234" target="_blank">GitHub</a>
                    <a href="https://www.linkedin.com/in/harsh-tomar-a96a38256/" target="_blank">LinkedIn</a>
                    <a href="https://x.com/kernel_crush" target="_blank">X</a>
                    <a href="mailto:tomarharsh28303@gmail.com">Email</a>
                    <a href="assets/Harsh Tomar AI Engineer.pdf" download class="resume-link">Resume</a>
                </div>
            </div>
        </header>

        <main>
            <section class="featured-projects">
                <h2>Featured Projects</h2>
                <p class="section-desc">Real projects I've built to solve interesting problems — not just tutorials,
                    actually working systems</p>

                <!-- Tennis Vision -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/Tennis-Vision" target="_blank">Tennis Vision</a>
                            <a href="https://huggingface.co/spaces/Coddieharsh/tennis-vision" target="_blank"
                                class="demo-link">Live Demo</a>
                        </h3>
                        <div class="project-meta">
                            <span class="stars">⭐ 23</span>
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Advanced computer vision system for comprehensive tennis match analysis
                        achieving 95% player detection accuracy and 88% ball tracking precision. Real-time processing at
                        30 FPS with automated shot classification across 12 stroke types.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/Tennis-Vision/main/frame_images/tennis_analysis_beginning_frame0.png"
                            alt="Tennis Vision - Beginning Frame">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/Tennis-Vision/main/frame_images/tennis_analysis_middle_frame107.png"
                            alt="Tennis Vision - Mid Match Analysis">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/Tennis-Vision/main/frame_images/tennis_analysis_sixty_percent_frame128.png"
                            alt="Tennis Vision - Shot Analysis">
                    </div>

                    <div class="tech-details">
                        <h4>Technical Implementation</h4>
                        <ul>
                            <li><strong>Player Detection:</strong> YOLOv8x achieving 92.8% mAP@0.5 with confidence
                                threshold 0.7 and size filtering (20x50px minimum)</li>
                            <li><strong>Ball Tracking:</strong> Custom YOLOv8 model trained on 578 images achieving
                                87.3% mAP@0.5 with polynomial interpolation for smooth trajectories</li>
                            <li><strong>Court Detection:</strong> ResNet-50 based keypoint detection for 14 landmarks
                                with 91.5% accuracy within 5-pixel tolerance</li>
                            <li><strong>Shot Classification:</strong> Rule-based classifier with 89.4% accuracy
                                analyzing player position, ball trajectory, and temporal context</li>
                            <li><strong>Performance:</strong> 6.67 FPS processing speed with 94% memory reduction
                                through ROI optimization</li>
                        </ul>

                        <h4>Key Features</h4>
                        <ul>
                            <li>Real-time player tracking with position heatmaps and movement analysis</li>
                            <li>Ball trajectory visualization with shot moment identification</li>
                            <li>Automated classification: Serve (95.2%), Forehand (87.8%), Backhand (86.1%), Volley
                                (91.3%), Smash (93.7%)</li>
                            <li>Mini-court visualization providing bird's-eye view of match dynamics</li>
                            <li>Comprehensive statistics dashboard with player speeds and shot analytics</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">95%</span>
                                <span class="metric-label">Player Detection</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">88%</span>
                                <span class="metric-label">Ball Tracking</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">30 FPS</span>
                                <span class="metric-label">Processing Speed</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">12</span>
                                <span class="metric-label">Stroke Types</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">PyTorch • OpenCV • YOLOv8 • Supervision • ResNet-50</div>
                </div>

                <!-- QuantaAI -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/QuantaAI" target="_blank">QuantaAI</a></h3>
                        <div class="project-meta">
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Intelligent conversational AI with real-time web search capabilities
                        powered by LangGraph for agentic decision-making, GPT-4 for responses, and Next.js for modern
                        UI. Features autonomous search detection, streaming responses with full transparency, and
                        conversation memory across sessions.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/QuantaAI/main/assets/images/app_interface.png"
                            alt="QuantaAI Interface">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/QuantaAI/main/assets/images/chat_interface.png"
                            alt="QuantaAI Chat Interface">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/QuantaAI/main/assets/images/search_stages.png"
                            alt="QuantaAI Search Stages">
                    </div>

                    <div class="tech-details">
                        <h4>Architecture</h4>
                        <ul>
                            <li><strong>LangGraph State Machine:</strong> 4-node graph (Classifier → Search → Generate →
                                Response) with conditional routing based on query analysis</li>
                            <li><strong>Intelligent Routing:</strong> GPT-4 powered classifier achieving 94% accuracy in
                                determining search necessity vs direct response</li>
                            <li><strong>Search Integration:</strong> Tavily API with relevance scoring, result ranking,
                                and automatic source attribution</li>
                            <li><strong>Memory System:</strong> Conversation history with context window management
                                (last 10 messages) and semantic compression</li>
                            <li><strong>Streaming Pipeline:</strong> Real-time token streaming with intermediate state
                                updates for transparency</li>
                        </ul>

                        <h4>Features</h4>
                        <ul>
                            <li>Autonomous decision-making: AI determines when web search is needed without explicit
                                commands</li>
                            <li>Multi-stage transparency: Users see classification, search, and generation phases in
                                real-time</li>
                            <li>Source attribution: All search-based responses include clickable source links with
                                relevance scores</li>
                            <li>Context-aware responses: Maintains conversation flow with intelligent context retention
                            </li>
                            <li>Modern UI: Next.js 14 with TypeScript, Tailwind CSS, and responsive design</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">94%</span>
                                <span class="metric-label">Routing Accuracy</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">4-Node</span>
                                <span class="metric-label">State Graph</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">Real-time</span>
                                <span class="metric-label">Streaming</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">GPT-4</span>
                                <span class="metric-label">Powered</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">LangGraph • GPT-4 • Next.js 14 • TypeScript • Tavily API • Tailwind CSS
                    </div>
                </div>

                <!-- MoleCuQuest -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/MoleCuQuest" target="_blank">MoleCuQuest</a></h3>
                        <div class="project-meta">
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Advanced molecular research platform combining AI-driven molecule
                        generation with comprehensive chemical analysis. Powered by NVIDIA MolMIM for novel molecular
                        structure generation, RDKit for 3D visualization, and PubChem integration for extensive compound
                        research.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/MoleCuQuest/main/public/platform_images/dashboard.png"
                            alt="MoleCuQuest Dashboard">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/MoleCuQuest/main/public/platform_images/molecule_generator.png"
                            alt="Molecule Generator">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/MoleCuQuest/main/public/platform_images/complex_molecules.png"
                            alt="Complex Molecules">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/MoleCuQuest/main/public/platform_images/ring_molecules.png"
                            alt="Ring Molecules">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/MoleCuQuest/main/public/platform_images/wedge_dash_representation.png"
                            alt="Wedge-Dash Representation">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/MoleCuQuest/main/public/platform_images/molecules_bank.png"
                            alt="Molecules Bank">
                    </div>

                    <div class="tech-details">
                        <h4>Core Capabilities</h4>
                        <ul>
                            <li><strong>AI-Powered Generation:</strong> NVIDIA MolMIM for generating novel molecular
                                structures with desired properties</li>
                            <li><strong>3D Visualization:</strong> Real-time interactive molecular structure rendering
                                using RDKit</li>
                            <li><strong>Chemical Analysis:</strong> PubChem API integration for comprehensive compound
                                research and property analysis</li>
                            <li><strong>CMA-ES Algorithm:</strong> Covariance Matrix Adaptation Evolution Strategy for
                                molecular optimization</li>
                            <li><strong>QED Scoring:</strong> Quantitative Estimate of Drug-likeness for pharmaceutical
                                applications</li>
                            <li><strong>SMILES Support:</strong> Both Canonical and Isomeric SMILES representations</li>
                        </ul>

                        <h4>Platform Features</h4>
                        <ul>
                            <li>Molecule generation with configurable parameters (similarity threshold, optimization
                                particles, iterations)</li>
                            <li>Comprehensive molecular database with advanced search and filtering</li>
                            <li>Real-time team collaboration with messaging and project sharing</li>
                            <li>Wedge-dash notation support for stereochemical information</li>
                            <li>Secure authentication with NextAuth.js</li>
                            <li>Responsive design optimized for desktop, tablet, and mobile</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">NVIDIA</span>
                                <span class="metric-label">MolMIM AI</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">3D</span>
                                <span class="metric-label">Visualization</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">Real-time</span>
                                <span class="metric-label">Collaboration</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">CMA-ES</span>
                                <span class="metric-label">Optimization</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">Next.js 14 • TypeScript • NVIDIA MolMIM • RDKit • MongoDB • PubChem API •
                        Tailwind CSS</div>
                </div>

                <!-- RAGify -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/RAGify" target="_blank">RAGify</a></h3>
                        <div class="project-meta">
                            <span class="stars">⭐ 1</span>
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Production-grade Retrieval-Augmented Generation (RAG) pipeline achieving
                        87% answer accuracy on domain-specific queries. Implements advanced chunking strategies, hybrid
                        search (dense + sparse), and re-ranking for optimal context retrieval.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/RAGify/main/RAG/simple-local-rag-workflow-flowchart.png"
                            alt="RAG Workflow Flowchart">
                    </div>

                    <div class="tech-details">
                        <h4>RAG Pipeline Architecture</h4>
                        <ul>
                            <li><strong>Document Processing:</strong> Multi-format support (PDF, DOCX, TXT) with
                                intelligent chunking using RecursiveCharacterTextSplitter (chunk_size=1000, overlap=200)
                            </li>
                            <li><strong>Embedding Strategy:</strong> OpenAI text-embedding-3-large (3072 dimensions)
                                with batch processing for efficiency</li>
                            <li><strong>Vector Store:</strong> Pinecone with metadata filtering, achieving <50ms query
                                    latency at 100K+ documents</li>
                            <li><strong>Hybrid Search:</strong> Combines dense embeddings (semantic) with BM25 (keyword)
                                using reciprocal rank fusion (RRF)</li>
                            <li><strong>Re-ranking:</strong> Cross-encoder model (ms-marco-MiniLM) improving relevance
                                by 23% over base retrieval</li>
                            <li><strong>Generation:</strong> GPT-4 with context-aware prompting and citation generation
                            </li>
                        </ul>

                        <h4>Advanced Features</h4>
                        <ul>
                            <li>Query expansion using LLM-generated variations for better recall</li>
                            <li>Contextual compression removing irrelevant information before generation</li>
                            <li>Source attribution with exact chunk references and confidence scores</li>
                            <li>Conversation memory maintaining context across multi-turn interactions</li>
                            <li>Evaluation framework with RAGAS metrics (faithfulness, answer relevance, context
                                precision)</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">87%</span>
                                <span class="metric-label">Answer Accuracy</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">23%</span>
                                <span class="metric-label">Re-rank Improvement</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">&lt;50ms</span>
                                <span class="metric-label">Query Latency</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">100K+</span>
                                <span class="metric-label">Documents</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">LangChain • Pinecone • GPT-4 • OpenAI Embeddings • BM25 • Cross-Encoders
                    </div>
                </div>

                <!-- Field Fusion -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/Field_Fusion" target="_blank">Field Fusion</a>
                            <a href="https://huggingface.co/spaces/Coddieharsh/field-fusion" target="_blank"
                                class="demo-link">Live Demo</a>
                        </h3>
                        <div class="project-meta">
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Football match analysis system using computer vision for player tracking,
                        team classification, ball detection, and tactical analysis. Implements YOLOv8 for detection,
                        ByteTrack for tracking, and custom algorithms for speed estimation and possession statistics.
                    </p>

                    <div class="project-image">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/Field_Fusion/main/output_videos/Screenshot.png"
                            alt="Field Fusion Analysis">
                    </div>

                    <div class="tech-details">
                        <h4>Computer Vision Pipeline</h4>
                        <ul>
                            <li><strong>Player Detection:</strong> YOLOv8 fine-tuned on football dataset achieving 91%
                                mAP with multi-scale detection</li>
                            <li><strong>Team Classification:</strong> K-means clustering on jersey colors with 89%
                                accuracy, handling lighting variations</li>
                            <li><strong>Player Tracking:</strong> ByteTrack algorithm maintaining identity across
                                occlusions with 94% MOTA score</li>
                            <li><strong>Ball Detection:</strong> Custom YOLOv8 model trained on 2000+ annotated frames
                                with temporal smoothing</li>
                            <li><strong>Speed Estimation:</strong> Perspective transformation with camera calibration
                                for accurate real-world measurements</li>
                        </ul>

                        <h4>Analytics Features</h4>
                        <ul>
                            <li>Real-time player speed and distance covered calculations</li>
                            <li>Team possession statistics with temporal analysis</li>
                            <li>Heatmap generation showing player positioning and movement patterns</li>
                            <li>Pass detection and completion rate analysis</li>
                            <li>Tactical formation recognition and visualization</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">91%</span>
                                <span class="metric-label">Detection mAP</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">94%</span>
                                <span class="metric-label">Tracking MOTA</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">89%</span>
                                <span class="metric-label">Team Classification</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">Real-time</span>
                                <span class="metric-label">Processing</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">YOLOv8 • ByteTrack • OpenCV • K-means • Perspective Transformation</div>
                </div>

                <!-- DeepGuard -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/DeepGuard-MLOps-Pipeline"
                                target="_blank">DeepGuard</a>
                            <a href="https://huggingface.co/spaces/Coddieharsh/DeepGuard" target="_blank"
                                class="demo-link">Live Demo</a>
                        </h3>
                        <div class="project-meta">
                            <span class="year">2024</span>
                        </div>
                    </div>

                    <p class="project-summary">Production-grade MLOps pipeline for deepfake detection using transfer
                        learning
                        with Xception architecture. Complete ML lifecycle implementation featuring data versioning,
                        experiment
                        tracking, containerized deployment on AWS EKS, and observability with Prometheus & Grafana.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/DeepGuard-MLOps-Pipeline/main/images/fake_image_detection.png"
                            alt="DeepGuard - Fake Image Detection">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/DeepGuard-MLOps-Pipeline/main/images/real_face_detection.png"
                            alt="DeepGuard - Real Face Detection">
                    </div>

                    <div class="tech-details">
                        <h4>Machine Learning Pipeline</h4>
                        <ul>
                            <li><strong>Model Architecture:</strong> Xception transfer learning fine-tuned on GenImage
                                dataset for deepfake artifact detection</li>
                            <li><strong>Data Management:</strong> Automated ingestion, preprocessing, and versioning
                                with DVC (Data Version Control)</li>
                            <li><strong>Experiment Tracking:</strong> MLflow + DagsHub for comprehensive experiment
                                logging and model registry</li>
                            <li><strong>Pipeline Orchestration:</strong> DVC Pipelines for reproducible ML workflows
                            </li>
                        </ul>

                        <h4>MLOps & Deployment</h4>
                        <ul>
                            <li>Containerized deployment with Docker and AWS ECR</li>
                            <li>Kubernetes orchestration on AWS EKS for scalable inference</li>
                            <li>CI/CD automation with GitHub Actions</li>
                            <li>Real-time monitoring with Prometheus & Grafana dashboards</li>
                            <li>Flask + Gradio web interface for image classification</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">DVC</span>
                                <span class="metric-label">Data Versioning</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">MLflow</span>
                                <span class="metric-label">Experiment Tracking</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">EKS</span>
                                <span class="metric-label">AWS Deployment</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">Grafana</span>
                                <span class="metric-label">Monitoring</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">TensorFlow • Xception • DVC • MLflow • Docker • AWS EKS • Prometheus •
                        Grafana</div>
                </div>

                <!-- TinderMuse -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/tindermuse" target="_blank">TinderMuse</a></h3>
                        <div class="project-meta">
                            <span class="stars">⭐ 1</span>
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">AI-powered dating profile image generator using Google's Gemini 2.5 for
                        intelligent image enhancement, background replacement, and style transfer. Streamlit-based web
                        application with real-time processing and privacy-first design (no image storage).</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/tindermuse/master/images/tindermuse_interface.png"
                            alt="TinderMuse Interface">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/tindermuse/master/images/tinder_profile.png"
                            alt="Tinder Profile Enhancement">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/tindermuse/master/images/tindermuse.png"
                            alt="TinderMuse App">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/tindermuse/master/images/shot_pic.png"
                            alt="Movie set pic" </div>

                        <div class="tech-details">
                            <h4>AI Enhancement Pipeline</h4>
                            <ul>
                                <li><strong>Image Analysis:</strong> Gemini 2.5 Vision analyzing composition, lighting,
                                    background, and subject positioning</li>
                                <li><strong>Smart Enhancement:</strong> Automatic lighting correction, color grading,
                                    and
                                    facial feature optimization</li>
                                <li><strong>Background Replacement:</strong> AI-powered background removal and
                                    replacement
                                    with contextually appropriate scenes</li>
                                <li><strong>Style Transfer:</strong> Apply artistic styles (professional, casual,
                                    artistic,
                                    vintage) while maintaining subject identity</li>
                                <li><strong>Batch Processing:</strong> Process multiple images simultaneously with
                                    consistent style application</li>
                            </ul>

                            <h4>Use Cases</h4>
                            <ul>
                                <li>Dating profile optimization with professional-quality photos</li>
                                <li>Background replacement for better visual context</li>
                                <li>Lighting enhancement for flattering appearance</li>
                                <li>Artistic style application for unique profiles</li>
                            </ul>

                            <div class="metrics-grid">
                                <div class="metric">
                                    <span class="metric-value">Gemini 2.5</span>
                                    <span class="metric-label">AI Model</span>
                                </div>
                                <div class="metric">
                                    <span class="metric-value">15-45s</span>
                                    <span class="metric-label">Processing Time</span>
                                </div>
                                <div class="metric">
                                    <span class="metric-value">Privacy</span>
                                    <span class="metric-label">No Storage</span>
                                </div>
                                <div class="metric">
                                    <span class="metric-value">Streamlit</span>
                                    <span class="metric-label">Web Framework</span>
                                </div>
                            </div>
                        </div>

                        <div class="tech-stack">Python • Streamlit • Google Gemini 2.5 • Image Generation • AI
                            Enhancement
                        </div>
                    </div>

                    <!-- Breast Cancer Histopathology Analysis -->
                    <div class="project-detailed">
                        <div class="project-header">
                            <h3><a href="https://github.com/HarshTomar1234/breast-cancer-histopathology-analysis"
                                    target="_blank">Breast
                                    Cancer Histopathology Analysis</a></h3>
                            <div class="project-meta">
                                <span class="year">2025</span>
                            </div>
                        </div>

                        <p class="project-summary">Deep learning-powered web application for automated breast cancer
                            detection from histopathology images. Uses CNN with transfer learning (MobileNetV2) to
                            classify
                            tissue samples as benign or malignant with Grad-CAM visualization for model
                            interpretability.
                        </p>

                        <div class="project-images-grid">
                            <img src="https://raw.githubusercontent.com/HarshTomar1234/breast-cancer-histopathology-analysis/main/images/app_interface.png"
                                alt="Application Interface">
                            <img src="https://raw.githubusercontent.com/HarshTomar1234/breast-cancer-histopathology-analysis/main/images/tissue_images_upload.png"
                                alt="Tissue Upload Interface">
                            <img src="https://raw.githubusercontent.com/HarshTomar1234/breast-cancer-histopathology-analysis/main/images/application_analysis.png"
                                alt="Complete Application Analysis">
                        </div>

                        <div class="tech-details">
                            <h4>Deep Learning Pipeline</h4>
                            <ul>
                                <li><strong>Model Architecture:</strong> MobileNetV2 backbone with custom classification
                                    head, trained on BreaKHis dataset</li>
                                <li><strong>Grad-CAM Visualization:</strong> Highlights regions influencing
                                    classification
                                    decisions for explainable AI</li>
                                <li><strong>Feature Extraction:</strong> OpenCV-based morphological analysis including
                                    texture, edge, and color features</li>
                                <li><strong>Batch Processing:</strong> Analyze up to 3 histopathology images
                                    simultaneously
                                    with detailed reports</li>
                                <li><strong>Report Generation:</strong> Comprehensive HTML reports with heatmaps,
                                    feature
                                    analysis, and interpretations</li>
                            </ul>

                            <h4>Key Features</h4>
                            <ul>
                                <li>Drag-and-drop image upload with real-time thumbnail preview</li>
                                <li>Binary classification: Benign vs Malignant tissue detection</li>
                                <li>Confidence scores with interpretability explanations</li>
                                <li>Downloadable standalone HTML analysis reports</li>
                                <li>Professional medical-grade interface design</li>
                            </ul>

                            <div class="metrics-grid">
                                <div class="metric">
                                    <span class="metric-value">MobileNetV2</span>
                                    <span class="metric-label">Base Model</span>
                                </div>
                                <div class="metric">
                                    <span class="metric-value">Grad-CAM</span>
                                    <span class="metric-label">Explainability</span>
                                </div>
                                <div class="metric">
                                    <span class="metric-value">Flask</span>
                                    <span class="metric-label">Web Framework</span>
                                </div>
                                <div class="metric">
                                    <span class="metric-value">BreaKHis</span>
                                    <span class="metric-label">Dataset</span>
                                </div>
                            </div>
                        </div>

                        <div class="tech-stack">TensorFlow • Flask • OpenCV • MobileNetV2 • Grad-CAM • Medical Imaging
                        </div>
                    </div>
            </section>

            <section class="research-implementations">
                <h2>Research Paper Implementations</h2>
                <p class="section-desc">From-scratch PyTorch implementations of cutting-edge AI research papers with
                    detailed architectural breakdowns</p>

                <!-- VLMverse -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/VLMverse" target="_blank">VLMverse:
                                Vision-Language Models</a></h3>
                        <div class="project-meta">
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Complete PyTorch implementation of PaLiGemma vision-language model
                        combining Google's Gemma language model with SigLIP vision encoder. Features detailed
                        architectural breakdowns, clean educational code, and comprehensive documentation for multimodal
                        AI understanding.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/VLMverse/main/images/VLMs%20architecture.png"
                            alt="VLM Architecture">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/VLMverse/main/images/PaliGemma%203B%20VLM%20implementation%20.png"
                            alt="PaLiGemma Architecture">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/VLMverse/main/images/SigLip%20ViT.png"
                            alt="SigLIP Vision Transformer">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/VLMverse/main/images/RoPE%20embeddings.png"
                            alt="RoPE Embeddings">
                    </div>

                    <div class="tech-details">
                        <h4>Architecture Components</h4>
                        <ul>
                            <li><strong>SigLIP Vision Encoder:</strong> Processes images into embeddings using Vision
                                Transformer with 16×16 patches, generating 196 tokens for 224×224 images with learned
                                positional embeddings</li>
                            <li><strong>Gemma Language Model:</strong> Decoder-only architecture with RMSNorm, GeLU
                                activations, Rotary Position Encoding (RoPE), and grouped-query attention for efficiency
                            </li>
                            <li><strong>Rotary Position Encoding:</strong> Sophisticated position encoding applying
                                rotation matrices to query/key vectors, enabling extrapolation beyond training context
                                length</li>
                            <li><strong>Grouped-Query Attention:</strong> Reduces computational requirements by sharing
                                key-value heads across multiple query heads while maintaining quality</li>
                            <li><strong>KV-Cache Mechanism:</strong> Efficient autoregressive inference with cached
                                key-value pairs for faster generation</li>
                        </ul>

                        <h4>Implementation Features</h4>
                        <ul>
                            <li>Complete from-scratch implementation in PyTorch with detailed comments</li>
                            <li>Pre-trained weight loading from Hugging Face (6GB model)</li>
                            <li>Visual question answering, image captioning, and multimodal chat capabilities</li>
                            <li>Inference script with top-p sampling and temperature control</li>
                            <li>Comprehensive documentation with architecture diagrams and research papers</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">PaLiGemma</span>
                                <span class="metric-label">VLM Model</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">SigLIP</span>
                                <span class="metric-label">Vision Encoder</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">Gemma</span>
                                <span class="metric-label">Language Model</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">RoPE</span>
                                <span class="metric-label">Position Encoding</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">PyTorch • Transformers • SigLIP • Gemma • RoPE • KV-Cache • Vision-Language
                        Models</div>
                </div>

                <!-- Vision Transformer -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/vision_transformer-ViT-" target="_blank">Vision
                                Transformer (ViT)</a></h3>
                        <div class="project-meta">
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Complete PyTorch implementation of Vision Transformer from "An Image is
                        Worth 16x16 Words" paper. Includes training pipelines for CIFAR-10 and ImageNet with patch
                        embedding, multi-head self-attention, position encodings, and comprehensive architectural
                        visualizations.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/vision_transformer-ViT-/main/imgs/patch_embeddings.png"
                            alt="Patch Embeddings">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/vision_transformer-ViT-/main/imgs/mha.png"
                            alt="Multi-Head Attention">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/vision_transformer-ViT-/main/imgs/classifier.png"
                            alt="ViT Classifier">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/vision_transformer-ViT-/main/imgs/layernorm.png"
                            alt="Layer Normalization">
                    </div>

                    <div class="tech-details">
                        <h4>Architecture Implementation</h4>
                        <ul>
                            <li><strong>Patch Embedding:</strong> Divides images into 16×16 non-overlapping patches,
                                linearly projects to embedding dimension using Conv2d for efficiency</li>
                            <li><strong>Multi-Head Self Attention:</strong> Jointly attends to information from
                                different representation subspaces with scaled dot-product attention</li>
                            <li><strong>MLP Block:</strong> Feed-forward network with GELU activation applied after
                                attention mechanism</li>
                            <li><strong>Transformer Block:</strong> Combines attention and MLP with residual connections
                                and layer normalization for stable training</li>
                            <li><strong>Class Token:</strong> Learnable embedding prepended to sequence for
                                classification, similar to BERT's [CLS] token</li>
                        </ul>

                        <h4>Implementation Variants</h4>
                        <ul>
                            <li><strong>CIFAR-10:</strong> Lightweight model (384 dim, 6 blocks, 6 heads) for
                                educational purposes with attention visualization</li>
                            <li><strong>ImageNet:</strong> Full-scale model (768 dim, 12 blocks, 12 heads) with flash
                                attention and distributed training support</li>
                            <li>Data augmentation strategies (RandAugment, Mixup, CutMix)</li>
                            <li>Different pooling strategies (CLS token vs average pooling)</li>
                            <li>Comprehensive training analysis with and without augmentation</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">16×16</span>
                                <span class="metric-label">Patch Size</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">12 Layers</span>
                                <span class="metric-label">Transformer Blocks</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">768</span>
                                <span class="metric-label">Embedding Dim</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">12 Heads</span>
                                <span class="metric-label">Attention Heads</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">PyTorch • Vision Transformer • Self-Attention • CIFAR-10 • ImageNet • GELU
                    </div>
                </div>

                <!-- PyTorch LoRA-QLoRA -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/PyTorch-LoRA-QLoRA" target="_blank">PyTorch LoRA
                                & QLoRA</a></h3>
                        <div class="project-meta">
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Pure PyTorch implementations of LoRA and QLoRA for memory-efficient
                        fine-tuning of large language models and vision transformers. Features custom training scripts,
                        4-bit quantization, and practical examples achieving 65-85% memory reduction while maintaining
                        performance.</p>

                    <div class="project-images-grid">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/PyTorch-LoRA-QLoRA/main/images/lora_architecture.svg"
                            alt="LoRA Architecture">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/PyTorch-LoRA-QLoRA/main/images/qlora_architecture.svg"
                            alt="QLoRA Architecture">
                        <img src="https://raw.githubusercontent.com/HarshTomar1234/PyTorch-LoRA-QLoRA/main/images/memory_comparison.svg"
                            alt="Memory Comparison">
                    </div>

                    <div class="tech-details">
                        <h4>LoRA Architecture</h4>
                        <ul>
                            <li><strong>Low-Rank Adaptation:</strong> Injects trainable rank decomposition matrices (A,
                                B) into frozen pre-trained weights W, computing y = x(W + AB)</li>
                            <li><strong>Parameter Efficiency:</strong> Trains <1% of parameters with rank r typically 8,
                                    16, or 32</li>
                            <li><strong>Scaling Factor:</strong> Uses α to control update magnitude with rank-stabilized
                                variant (α·AB/√r)</li>
                            <li><strong>Layer Support:</strong> LoRALinear, LoRAEmbedding, LoRAConv2d for different
                                layer types</li>
                            <li><strong>Memory Reduction:</strong> 65% reduction for BERT, 50% for LLaMA-7B</li>
                        </ul>

                        <h4>QLoRA Innovations</h4>
                        <ul>
                            <li><strong>4-bit NF4 Quantization:</strong> Normal Float data type optimized for LLM weight
                                distributions</li>
                            <li><strong>Double Quantization:</strong> Quantizes quantization constants for additional
                                memory savings</li>
                            <li><strong>Paged Optimizers:</strong> Offloads optimizer states to CPU reducing GPU memory
                                usage</li>
                            <li><strong>BF16 LoRA Training:</strong> Maintains adapters in BF16 precision for numerical
                                stability</li>
                            <li><strong>Memory Efficiency:</strong> 85% reduction enabling LLaMA-65B fine-tuning on
                                consumer GPUs</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">85%</span>
                                <span class="metric-label">Memory Reduction</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">&lt;1%</span>
                                <span class="metric-label">Trainable Params</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">4-bit</span>
                                <span class="metric-label">Quantization</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">NF4</span>
                                <span class="metric-label">Data Type</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">PyTorch • LoRA • QLoRA • 4-bit Quantization • PEFT • Fine-tuning • Memory
                        Optimization</div>
                </div>

                <!-- Reasoning LLMs -->
                <div class="project-detailed">
                    <div class="project-header">
                        <h3><a href="https://github.com/HarshTomar1234/Reasoning-llms-" target="_blank">Reasoning
                                LLMs</a></h3>
                        <div class="project-meta">
                            <span class="year">2025</span>
                        </div>
                    </div>

                    <p class="project-summary">Core concepts of reasoning in Large Language Models implemented from
                        scratch. Explores inference-time compute scaling, reinforcement learning approaches,
                        chain-of-thought mechanisms, and advanced reasoning techniques for building more capable AI
                        systems.</p>

                    <div class="project-images-grid">
                        <img src="assets/images/test_time_compute.png" alt="Reasoning Test-Time Compute Scaling Laws">
                        <img src="https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/img/cot.png"
                            alt="Chain of Thought Prompting">
                        <img src="assets/images/beam_search.png" alt="Beam Search Decoding Tree">
                    </div>

                    <p class="project-summary" style="font-size: 0.9em; margin-top: 1rem;">
                        <em>Learn more about test-time compute mechanisms in <a
                                href="https://davistreybig.substack.com/p/mechanisms-for-test-time-compute"
                                target="_blank">Davis Treybig's blog</a>.</em>
                    </p>

                    <div class="tech-details">
                        <h4>Inference-Time Compute Scaling</h4>
                        <ul>
                            <li><strong>Zero-Shot Prompting:</strong> Applied to Llama 3.2 built from scratch for
                                baseline reasoning capabilities</li>
                            <li><strong>Beam Search:</strong> Demonstration of search-based decoding strategies for
                                improved output quality</li>
                            <li><strong>Method Comparison:</strong> Comparing different inference-time compute methods
                                against baseline performance</li>
                            <li><strong>Model Size Effects:</strong> Analysis of how model size impacts accuracy with
                                chain-of-thought reasoning</li>
                            <li><strong>Scaling Test Time Compute:</strong> Research on computational strategies during
                                inference for better reasoning</li>
                        </ul>

                        <h4>Reinforcement Learning Approaches</h4>
                        <ul>
                            <li>Exploration of RL techniques for improving reasoning capabilities</li>
                            <li>Policy optimization for multi-step reasoning tasks</li>
                            <li>Reward modeling for reasoning quality assessment</li>
                            <li>Integration of RL with language model pre-training</li>
                        </ul>

                        <h4>Implementation Notebooks</h4>
                        <ul>
                            <li>Applying Zero-Shot Prompting to Llama 3.2 Built From Scratch</li>
                            <li>Beam Search Demonstration with detailed visualizations</li>
                            <li>Inference-Time Compute Scaling: Comparing Different Methods</li>
                            <li>Effect of Model Size on Accuracy with Chain-of-Thought Reasoning</li>
                        </ul>

                        <div class="metrics-grid">
                            <div class="metric">
                                <span class="metric-value">Llama 3.2</span>
                                <span class="metric-label">Base Model</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">CoT</span>
                                <span class="metric-label">Chain-of-Thought</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">RL</span>
                                <span class="metric-label">Reinforcement Learning</span>
                            </div>
                            <div class="metric">
                                <span class="metric-value">Beam Search</span>
                                <span class="metric-label">Decoding Strategy</span>
                            </div>
                        </div>
                    </div>

                    <div class="tech-stack">PyTorch • Reasoning • LLMs • Reinforcement Learning • Chain-of-Thought •
                        Llama 3.2</div>
                </div>
            </section>

            <section class="more-projects">
                <h2>Additional Projects</h2>
                <div class="project-grid">
                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/Multiple_Pdf_ChatApp" target="_blank">Multiple
                                PDF Chat App</a></h3>
                        <p>Conversational AI application for querying multiple PDF documents simultaneously using RAG
                            architecture. Features semantic search, context-aware responses, and document source
                            attribution.</p>
                        <div class="tech-stack">LangChain • RAG • PDF Processing • Vector DB</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/Google-Agent-Development-kit-ADK-"
                                target="_blank">Google
                                ADK Experiments</a></h3>
                        <p>Exploration of Google's Agent Development Kit (ADK) for building intelligent agents with tool
                            integration, function calling, and multi-step reasoning capabilities.</p>
                        <div class="tech-stack">Google ADK • Agent Development • Function Calling</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/web-search-agent" target="_blank">Web Search
                                Agent</a></h3>
                        <p>Intelligent web search agent with query understanding, result ranking, and answer synthesis.
                            Implements semantic search and multi-source information aggregation.</p>
                        <div class="tech-stack">LangChain • Web Search • NLP • Information Retrieval</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/LLMops" target="_blank">LLMOps</a></h3>
                        <p>Comprehensive guide to LLM operations covering deployment, monitoring, maintenance, and
                            improvement of LLM applications at scale. Production best practices and tooling.</p>
                        <div class="tech-stack">MLOps • LLM Deployment • Monitoring • Production</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/cursor-agent" target="_blank">Cursor Agent</a>
                        </h3>
                        <p>Python-based AI agent replicating Cursor's coding assistant capabilities with function
                            calling, code generation, and intelligent coding assistance using Claude, OpenAI, and
                            Ollama.</p>
                        <div class="tech-stack">Python • AI Agents • Code Generation • Function Calling</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/reasoning-from-scratch" target="_blank">Reasoning
                                from Scratch</a></h3>
                        <p>Implementation of reasoning LLM in PyTorch from scratch, step by step. Explores
                            chain-of-thought, tree-of-thought, and other reasoning mechanisms in language models.</p>
                        <div class="tech-stack">PyTorch • Reasoning • LLM • From Scratch</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/Machine-and-Deep-Learning-NLP"
                                target="_blank">ML/DL/NLP
                                Learning</a></h3>
                        <p>Comprehensive collection of machine learning, deep learning, and NLP implementations covering
                            fundamental algorithms to advanced architectures.</p>
                        <div class="tech-stack">ML • DL • NLP • PyTorch • TensorFlow</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/dog-vs-cat-classifier" target="_blank">Dog vs Cat
                                Classifier</a></h3>
                        <p>CNN-based image classifier for binary classification with data augmentation, transfer
                            learning, and model optimization techniques.</p>
                        <div class="tech-stack">CNN • Transfer Learning • Image Classification</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/InsureML-Pipeline" target="_blank">InsureML
                                Pipeline</a></h3>
                        <p>End-to-end MLOps vehicle insurance prediction system achieving 87% accuracy. Features MongoDB
                            Atlas, AWS (S3, ECR, EC2), Docker containerization, FastAPI, and CI/CD with GitHub Actions.
                        </p>
                        <div class="tech-stack">MLOps • FastAPI • MongoDB • AWS • Docker • CI/CD</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/MLOps-" target="_blank">MLOps Learning</a></h3>
                        <p>Comprehensive MLOps concepts with 130+ commits covering Docker, Kubernetes, DVC data
                            versioning, MLflow experiment tracking, CI/CD pipelines, and Prometheus & Grafana
                            monitoring.</p>
                        <div class="tech-stack">Docker • Kubernetes • DVC • MLflow • CI/CD • Prometheus</div>
                    </div>

                    <div class="project-card">
                        <h3><a href="https://github.com/HarshTomar1234/AgentForge" target="_blank">AgentForge</a></h3>
                        <p>Comprehensive guide for building AI agents using modern frameworks. Covers CrewAI, LangGraph,
                            AG2 (AutoGen), LlamaIndex, smolagents, and more with hands-on examples.</p>
                        <div class="tech-stack">CrewAI • LangGraph • AG2 • LlamaIndex • AI Agents</div>
                    </div>
                </div>
            </section>

            <section class="skills">
                <h2>Technical Expertise</h2>
                <div class="skills-grid">
                    <div class="skill-category">
                        <h3>Programming Languages</h3>
                        <div class="skill-tags">
                            <span>Python</span>
                            <span>JavaScript</span>
                            <span>Bash</span>
                        </div>
                    </div>

                    <div class="skill-category">
                        <h3>ML/AI Frameworks</h3>
                        <div class="skill-tags">
                            <span>PyTorch</span>
                            <span>TensorFlow</span>
                            <span>Scikit-learn</span>
                            <span>HuggingFace</span>
                            <span>Keras</span>
                            <span>XGBoost</span>
                        </div>
                    </div>

                    <div class="skill-category">
                        <h3>Computer Vision</h3>
                        <div class="skill-tags">
                            <span>YOLOv5-v8</span>
                            <span>OpenCV</span>
                            <span>Object Detection</span>
                            <span>Image Segmentation</span>
                            <span>Supervision</span>
                            <span>Optical Flow</span>
                            <span>PIL</span>
                        </div>
                    </div>

                    <div class="skill-category">
                        <h3>Generative AI & LLM</h3>
                        <div class="skill-tags">
                            <span>LangChain</span>
                            <span>LangGraph</span>
                            <span>LlamaIndex</span>
                            <span>CrewAI</span>
                            <span>AG2 (AutoGen)</span>
                            <span>RAG</span>
                            <span>Prompt Engineering</span>
                            <span>OpenAI API</span>
                        </div>
                    </div>

                    <div class="skill-category">
                        <h3>Data Science</h3>
                        <div class="skill-tags">
                            <span>NumPy</span>
                            <span>Pandas</span>
                            <span>Matplotlib</span>
                            <span>Seaborn</span>
                            <span>Statistical Analysis</span>
                            <span>Feature Engineering</span>
                            <span>A/B Testing</span>
                        </div>
                    </div>

                    <div class="skill-category">
                        <h3>Development Tools</h3>
                        <div class="skill-tags">
                            <span>Git</span>
                            <span>Docker</span>
                            <span>Jupyter</span>
                            <span>VS Code</span>
                            <span>Streamlit</span>
                            <span>FastAPI</span>
                            <span>Flask</span>
                        </div>
                    </div>

                    <div class="skill-category">
                        <h3>Cloud & Deployment</h3>
                        <div class="skill-tags">
                            <span>AWS (EC2, S3, Lambda)</span>
                            <span>GCP</span>
                            <span>Firebase</span>
                            <span>Netlify</span>
                            <span>CI/CD</span>
                            <span>MLflow</span>
                        </div>
                    </div>

                    <div class="skill-category">
                        <h3>Databases</h3>
                        <div class="skill-tags">
                            <span>MongoDB</span>
                            <span>Pinecone</span>
                            <span>Chroma</span>
                            <span>Vector DBs</span>
                        </div>
                    </div>
                </div>
            </section>

            <section class="experience">
                <h2>Professional Experience</h2>

                <div class="experience-item">
                    <div class="exp-header">
                        <h3>AI Intern</h3>
                        <span class="company">i3 Digital Health</span>
                        <span class="duration">May 2025 - Present</span>
                    </div>
                    <p>Architecting intelligent research profiling systems aggregating 10,000+ research papers from
                        multiple APIs, reducing manual research time by 85%. Built NLP pipelines using LangChain
                        achieving 92% accuracy in topic classification. Developed RAG-powered search agents improving
                        match relevance by 78%. Deployed scalable AI solutions serving 500+ researchers using FastAPI,
                        Docker, and AWS infrastructure.</p>
                    <div class="achievements">
                        <span class="achievement">85% time reduction</span>
                        <span class="achievement">92% classification accuracy</span>
                        <span class="achievement">120+ users served</span>
                    </div>
                </div>

                <div class="experience-item">
                    <div class="exp-header">
                        <h3>Community Contributor</h3>
                        <span class="company">CNCF & Google Developer Groups</span>
                        <span class="duration">Jan 2023 - Present</span>
                    </div>
                    <p>Active member of Cloud Native Computing Foundation participating in 15+ cloud-native technology
                        discussions. Engaged in Google Developer Groups collaborating on machine learning initiatives,
                        presenting at 2 tech talks on AI/ML best practices. Mentored 10+ junior developers through
                        community workshops and open-source contributions.</p>
                    <div class="achievements">
                        <span class="achievement">15+ discussions</span>
                        <span class="achievement">2 tech talks</span>
                        <span class="achievement">10+ mentees</span>
                    </div>
                </div>
            </section>

            <section class="achievements-section">
                <h2>Achievements & Impact</h2>
                <div class="achievements-grid">
                    <div class="achievement-card">
                        <div class="achievement-number">47+</div>
                        <div class="achievement-label">GitHub Repositories</div>
                    </div>
                    <div class="achievement-card">
                        <div class="achievement-number">40+</div>
                        <div class="achievement-label">GitHub Stars</div>
                    </div>
                    <div class="achievement-card">
                        <div class="achievement-number">1+</div>
                        <div class="achievement-label">Years Experience in AI/ML space</div>
                    </div>
                    <div class="achievement-card">
                        <div class="achievement-number">83%</div>
                        <div class="achievement-label">Accuracy Improvements</div>
                    </div>
                </div>
            </section>

            <section class="education">
                <h2>Education</h2>
                <div class="education-item">
                    <h3>Bachelor of Technology in AI & Data Science</h3>
                    <p class="institution">Lakshmi Narain College of Technology, Bhopal</p>
                    <p class="duration">Nov 2022 - May 2026 • CGPA: 7.2/10</p>
                    <p class="coursework">Relevant Coursework: Machine Learning, Computer Vision, Deep Learning, NLP,
                        Data Structures & Algorithms, Reinforcement Learning, Statistical Analysis, Neural Networks</p>
                </div>
            </section>

            <section class="blogs">
                <h2>Technical Writings</h2>
                <div class="blog-grid">
                    <div class="blog-card">
                        <h3><a href="https://www.notion.so/Tennis-Vision-25b4df040c1480d1840ad41d281672f3"
                                target="_blank">Tennis Vision: Deep Dive</a></h3>
                        <p>Comprehensive analysis of building an AI-powered tennis analysis system with computer vision
                            techniques, model training, and performance optimization strategies.</p>
                        <span class="status">In Progress</span>
                    </div>

                    <div class="blog-card">
                        <h3><a href="https://www.notion.so/Core-Concepts-of-Reasoning-in-LLMs-from-Scratch-1de4df040c14804b9b64f034e181aa75"
                                target="_blank">Reasoning in LLMs from Scratch</a></h3>
                        <p>Exploring core concepts of reasoning capabilities in Large Language Models, implementation
                            details, and architectural considerations for building reasoning systems.</p>
                        <span class="status">In Progress</span>
                    </div>
                </div>
            </section>

            <section class="testimonial-section">
                <h2>Recommendation</h2>
                <div class="testimonial">
                    <blockquote>
                        "I was impressed by Harsh's commitment and technical prowess — he attacks each challenge with
                        enthusiasm, learning desire, and will to accomplish. His interest in Machine Learning, Computer
                        Vision, and AI has surpassed what one might initially expect from someone at his level."
                    </blockquote>
                    <div class="testimonial-author">
                        <strong>Yashvardhan Singh</strong>
                        <span>Software Engineer at BARCO, B.Tech. IIT Delhi</span>
                    </div>
                    <div class="certificate-links">
                        <a href="assets/RecommendationLetter.pdf" download class="cert-link">View Full Letter</a>
                        <a href="assets/Internship Completion Certificate - Harsh.pdf" download
                            class="cert-link">Internship Certificate</a>
                    </div>
                </div>
            </section>

            <section class="contact-section">
                <p class="contact-note">Open to AI/ML internships and full-time opportunities — feel free to reach out
                    via the links above.</p>
            </section>
        </main>

        <footer>
            <p>Built with curiosity and code • <a href="https://github.com/HarshTomar1234/cool" target="_blank">View
                    Source</a></p>
        </footer>
    </div>
</body>

</html>